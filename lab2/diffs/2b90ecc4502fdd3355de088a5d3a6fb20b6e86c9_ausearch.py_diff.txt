@@ -3,7 +3,18 @@ from abc import abstractmethod, ABC
 import bisect
 from copy import copy
 from functools import lru_cache
-from typing import Generic, List, Optional, Dict, Any, NamedTuple, Union, Set, Tuple, TypeVar
+from typing import (
+    Generic,
+    List,
+    Optional,
+    Dict,
+    Any,
+    NamedTuple,
+    Union,
+    Set,
+    Tuple,
+    TypeVar,
+)
 from ciphey.iface import (
     T,
     Cracker,
@@ -17,7 +28,8 @@ from ciphey.iface import (
     SearchResult,
     Decoder,
     DecoderComparer,
-    registry, Checker
+    registry,
+    Checker,
 )
 from datetime import datetime
 from loguru import logger
@@ -37,7 +49,7 @@ class DuplicateNode(Exception):
 
 @dataclass
 class AuSearchSuccessful(Exception):
-    target: 'Node'
+    target: "Node"
     info: str
 
 
@@ -45,19 +57,25 @@ class AuSearchSuccessful(Exception):
 class Node:
     # The root has no parent edge
     level: SearchLevel
-    parent: Optional['Edge'] = None
+    parent: Optional["Edge"] = None
     depth: int = 0
 
     @staticmethod
-    def decoding(config: Config, route: Union[Cracker, Decoder], result: Any, source: 'Node') -> 'Node':
+    def decoding(
+        config: Config, route: Union[Cracker, Decoder], result: Any, source: "Node"
+    ) -> "Node":
         if not config.cache.mark_ctext(result):
             raise DuplicateNode()
 
         checker: Checker = config.objs["checker"]
         target_type: type = config.objs["format"]["out"]
-        ret = Node(parent=None,
-                   level=SearchLevel(name=type(route).__name__.lower(), result=CrackResult(value=result)),
-                   depth=source.depth + 1)
+        ret = Node(
+            parent=None,
+            level=SearchLevel(
+                name=type(route).__name__.lower(), result=CrackResult(value=result)
+            ),
+            depth=source.depth + 1,
+        )
         edge = Edge(source=source, route=route, dest=ret)
         ret.parent = edge
         if type(result) == target_type:
@@ -67,7 +85,7 @@ class Node:
         return ret
 
     @staticmethod
-    def cracker(config: Config, edge_template: 'Edge', result: CrackResult) -> 'Node':
+    def cracker(config: Config, edge_template: "Edge", result: CrackResult) -> "Node":
         if not config.cache.mark_ctext(result.value):
             raise DuplicateNode()
 
@@ -75,9 +93,11 @@ class Node:
         target_type: type = config.objs["format"]["out"]
         # Edges do not directly contain containers, so this is fine
         edge = copy(edge_template)
-        ret = Node(parent=edge,
-                   level=SearchLevel(name=type(edge.route).__name__.lower(), result=result),
-                   depth=edge.source.depth + 1)
+        ret = Node(
+            parent=edge,
+            level=SearchLevel(name=type(edge.route).__name__.lower(), result=result),
+            depth=edge.source.depth + 1,
+        )
         edge.dest = ret
         if type(result.value) == target_type:
             check_res = checker(result.value)
@@ -99,7 +119,9 @@ class Node:
 
 
 def convert_edge_info(info: CrackInfo):
-    return cipheycore.ausearch_edge(info.success_likelihood, info.success_runtime, info.failure_runtime)
+    return cipheycore.ausearch_edge(
+        info.success_likelihood, info.success_runtime, info.failure_runtime
+    )
 
 
 @dataclass
@@ -111,7 +133,7 @@ class Edge:
     info: Optional[cipheycore.ausearch_edge] = None
 
 
-PriorityType = TypeVar('PriorityType')
+PriorityType = TypeVar("PriorityType")
 
 
 class PriorityWorkQueue(Generic[PriorityType, T]):
@@ -120,7 +142,10 @@ class PriorityWorkQueue(Generic[PriorityType, T]):
 
     def add_work(self, priority: PriorityType, work: List[T]) -> None:
         idx = bisect.bisect_left(self._sorted_priorities, priority)
-        if idx == len(self._sorted_priorities) or self._sorted_priorities[idx] != priority:
+        if (
+            idx == len(self._sorted_priorities)
+            or self._sorted_priorities[idx] != priority
+        ):
             self._sorted_priorities.insert(idx, priority)
         self._queues.setdefault(priority, []).extend(work)
 
@@ -139,7 +164,8 @@ class PriorityWorkQueue(Generic[PriorityType, T]):
         best_priority = self._sorted_priorities.pop(0)
         return self._queues.pop(best_priority)
 
-    def empty(self): return len(self._sorted_priorities) == 0
+    def empty(self):
+        return len(self._sorted_priorities) == 0
 
     def __init__(self):
         self._sorted_priorities = []
@@ -171,7 +197,9 @@ class AuSearch(Searcher):
 
         for i in self.get_crackers_for(type(res)):
             inst = self._config()(i)
-            additional_work.append(Edge(source=node, route=inst, info=convert_edge_info(inst.getInfo(res))))
+            additional_work.append(
+                Edge(source=node, route=inst, info=convert_edge_info(inst.getInfo(res)))
+            )
         if self.disable_priority:
             priority = 0
         elif self.invert_priority:
@@ -192,7 +220,9 @@ class AuSearch(Searcher):
             if res is None:
                 continue
             try:
-                new_node = Node.decoding(config=self._config(), route=inst, result=res, source=node)
+                new_node = Node.decoding(
+                    config=self._config(), route=inst, result=res, source=node
+                )
             except DuplicateNode:
                 continue
 
@@ -203,7 +233,9 @@ class AuSearch(Searcher):
         self.expand_crackers(node)
 
     def search(self, ctext: Any) -> Optional[SearchResult]:
-        logger.trace(f"""Beginning AuSearch with {"inverted" if self.invert_priority else "normal"} priority""")
+        logger.trace(
+            f"""Beginning AuSearch with {"inverted" if self.invert_priority else "normal"} priority"""
+        )
 
         try:
             root = Node.root(self._config(), ctext)
@@ -233,8 +265,10 @@ class AuSearch(Searcher):
                     logger.trace(f"{len(infos)} remaining on this level")
                     step_res = cipheycore.ausearch_minimise(infos)
                     edge: Edge = chunk.pop(step_res.index)
-                    logger.trace(f"Weight is currently {step_res.weight} "
-                                 f"when we pick {type(edge.route).__name__.lower()}")
+                    logger.trace(
+                        f"Weight is currently {step_res.weight} "
+                        f"when we pick {type(edge.route).__name__.lower()}"
+                    )
                     del infos[step_res.index]
 
                     # Expand the node
@@ -243,7 +277,9 @@ class AuSearch(Searcher):
                         continue
                     for i in res:
                         try:
-                            node = Node.cracker(config=self._config(), edge_template=edge, result=i)
+                            node = Node.cracker(
+                                config=self._config(), edge_template=edge, result=i
+                            )
                             self.recursive_expand(node)
                         except DuplicateNode:
                             continue
@@ -259,18 +295,26 @@ class AuSearch(Searcher):
         self._checker: Checker = config.objs["checker"]
         self._target_type: type = config.objs["format"]["out"]
         self.work = PriorityWorkQueue()  # Has to be defined here because of sharing
-        self.invert_priority = bool(distutils.util.strtobool(self._params()["invert_priority"]))
-        self.disable_priority = bool(distutils.util.strtobool(self._params()["disable_priority"]))
+        self.invert_priority = bool(
+            distutils.util.strtobool(self._params()["invert_priority"])
+        )
+        self.disable_priority = bool(
+            distutils.util.strtobool(self._params()["disable_priority"])
+        )
 
     @staticmethod
     def getParams() -> Optional[Dict[str, ParamSpec]]:
         return {
-            "invert_priority": ParamSpec(req=False,
-                                         desc="Causes more complex encodings to be looked at first. "
-                                              "Good for deeply buried encodings.",
-                                         default="False"),
-            "disable_priority": ParamSpec(req=False,
-                                         desc="Disables the priority queue altogether. "
-                                              "May be much faster, but will take *very* odd paths",
-                                         default="True")
+            "invert_priority": ParamSpec(
+                req=False,
+                desc="Causes more complex encodings to be looked at first. "
+                "Good for deeply buried encodings.",
+                default="False",
+            ),
+            "disable_priority": ParamSpec(
+                req=False,
+                desc="Disables the priority queue altogether. "
+                "May be much faster, but will take *very* odd paths",
+                default="True",
+            ),
         }
